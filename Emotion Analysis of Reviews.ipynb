{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "import autocorrect as autoCorr\n",
    "\n",
    "from senticnet.senticnet import SenticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FORMING EQUIVALENCE CLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we explore the given data to check the most common words that might associate to the 5 equivalence classes/aspects we have considered :\n",
    "- Taste\n",
    "- Quantity\n",
    "- Price\n",
    "- Delivery\n",
    "- Product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : No need to run this code section as the equivalence classes have been hardcoded after analyzing the dataset and from some intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Forming POS tags of the top 30000 words\n",
    "\n",
    "y = data['Text'].dropna()[0:30000]\n",
    "text = \"\"\n",
    "for i in y:\n",
    "    text = text + \" \" + i\n",
    "tokenized_word = word_tokenize(text)\n",
    "tokens = nltk.pos_tag(tokenized_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "# Performing lemmatization to get frequency of base forms of words\n",
    "    \n",
    "lem = WordNetLemmatizer()\n",
    "l1=[]\n",
    "for i in tokens:\n",
    "    if i[1].startswith('NN') | i[1].startswith('JJ'):\n",
    "        l1.append(lem.lemmatize(i[0],pos=get_wordnet_pos(i[1])))\n",
    "    \n",
    "# Removing the stop words from the most common words\n",
    "\n",
    "stop_words=set(stopwords.words(\"english\"))\n",
    "filtered_sent=[]\n",
    "for w in l1:\n",
    "    if w not in stop_words:\n",
    "        filtered_sent.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('/', 33601),\n",
       " ('br', 33326),\n",
       " ('<', 32958),\n",
       " ('>', 31820),\n",
       " ('good', 12089),\n",
       " ('coffee', 9710),\n",
       " ('flavor', 9356),\n",
       " ('product', 8826),\n",
       " ('great', 7424),\n",
       " ('taste', 6873),\n",
       " ('food', 6711),\n",
       " ('dog', 6590),\n",
       " ('tea', 5667),\n",
       " ('time', 5065),\n",
       " ('bag', 4267),\n",
       " ('treat', 4075),\n",
       " ('little', 4059),\n",
       " ('price', 4043),\n",
       " ('cup', 3592),\n",
       " ('Amazon', 3581),\n",
       " ('best', 3402),\n",
       " ('chip', 3277),\n",
       " ('store', 2998),\n",
       " ('brand', 2955),\n",
       " ('box', 2952),\n",
       " ('day', 2914),\n",
       " ('year', 2893),\n",
       " ('sugar', 2890),\n",
       " ('much', 2764),\n",
       " ('way', 2556),\n",
       " ('thing', 2547),\n",
       " ('water', 2521),\n",
       " ('small', 2487),\n",
       " ('chocolate', 2440),\n",
       " ('favorite', 2433),\n",
       " ('sweet', 2355),\n",
       " ('bit', 2300),\n",
       " ('first', 2235),\n",
       " ('cat', 2233),\n",
       " ('order', 2186),\n",
       " ('lot', 2096),\n",
       " ('ingredient', 2057),\n",
       " ('many', 2046),\n",
       " ('easy', 1979),\n",
       " ('healthy', 1962),\n",
       " ('something', 1948),\n",
       " ('bad', 1947),\n",
       " ('old', 1938),\n",
       " ('nice', 1882),\n",
       " ('strong', 1879),\n",
       " ('mix', 1858),\n",
       " ('delicious', 1841),\n",
       " ('one', 1839),\n",
       " ('hot', 1838),\n",
       " ('different', 1756),\n",
       " ('quality', 1725),\n",
       " ('regular', 1717),\n",
       " ('high', 1716),\n",
       " ('snack', 1711),\n",
       " ('size', 1709),\n",
       " ('review', 1707),\n",
       " ('stuff', 1705),\n",
       " ('free', 1646),\n",
       " ('drink', 1631),\n",
       " ('problem', 1624),\n",
       " ('oil', 1623),\n",
       " ('calorie', 1592),\n",
       " ('package', 1578),\n",
       " ('popcorn', 1563),\n",
       " ('big', 1547),\n",
       " ('%', 1543),\n",
       " ('perfect', 1524),\n",
       " ('milk', 1523),\n",
       " ('low', 1519),\n",
       " ('pack', 1518),\n",
       " ('month', 1513),\n",
       " ('hard', 1509),\n",
       " ('sure', 1503),\n",
       " ('juice', 1495),\n",
       " ('fresh', 1464),\n",
       " ('large', 1461),\n",
       " ('salt', 1457),\n",
       " ('local', 1366),\n",
       " ('tasty', 1351),\n",
       " ('less', 1347),\n",
       " ('happy', 1336),\n",
       " ('organic', 1326),\n",
       " ('whole', 1300),\n",
       " ('anything', 1261),\n",
       " ('item', 1260),\n",
       " ('Great', 1254),\n",
       " ('people', 1251),\n",
       " ('last', 1239),\n",
       " ('new', 1203),\n",
       " ('butter', 1187),\n",
       " ('amount', 1180),\n",
       " ('variety', 1178),\n",
       " ('star', 1177),\n",
       " ('fat', 1163),\n",
       " ('texture', 1156)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most frequent 100 words\n",
    "\n",
    "fdist = FreqDist(filtered_sent)\n",
    "fdist.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Final Equivalence Classes\n",
    "\n",
    "tasteClass = ['flavor','taste','sweet','delicious','tasty'\n",
    "         # self\n",
    "         ]\n",
    "foodClass = ['coffee','product','food','tea','bag','treat','chip','cup','brand',\n",
    "        'brew','sugar','thing','chocolate','order','ingredient','health',\n",
    "        'snack','quality','stuff','package','drink','milk','fresh','popcorn',\n",
    "        'organic','juice','texture','item','potato',\n",
    "        # self\n",
    "        'kettle','smell','hygiene','pancake','cocoa','gluten','soda','sugar',\n",
    "        'orange','bean','fruit','cracker','sauce','grocery','chicken','cookie',\n",
    "        'meal']\n",
    "priceClass = ['price',\n",
    "         # self\n",
    "         'purchase','$','cost','cheap','expensive','money']\n",
    "deliveryClass = ['packag',\n",
    "            # self\n",
    "            'day','deliver','speed','fast','slow','shipping']\n",
    "quantityClass = ['little','small','many','lot','size','big','low',\n",
    "            # self\n",
    "            'large','less','quantity','amount','number','several','full','half']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MICRO SENTENCE FORMATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we split the entire review into simple/micro sentences each of which affects the score of only one of the classes mentioned above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reviewToMicroSentences(compSent):\n",
    "    \n",
    "    # replacing the HTML breaks with whitespace\n",
    "    compSent = compSent.replace('<br />',' ')\n",
    "    \n",
    "    text_words = word_tokenize(compSent)   \n",
    "    text_pos = nltk.pos_tag(text_words)\n",
    "    \n",
    "    # Using autocorrect library for isolated spell correction\n",
    "    correctedSent = []\n",
    "    for ind, word in enumerate(text_words):\n",
    "        if text_pos[ind][1] not in (',', '.', ':'):\n",
    "            correctedSent.append(autoCorr.spell(word))\n",
    "        else:\n",
    "            correctedSent.append(word)\n",
    "            \n",
    "    text_pos = nltk.pos_tag(correctedSent)\n",
    "    \n",
    "    lastNoun = ''\n",
    "    \n",
    "    # initialise last noun as 'product' where first sentence starts with PRP/WDT\n",
    "    lastNoun = ('product','NN')\n",
    "    \n",
    "    microSent = []\n",
    "    currSent = []\n",
    "    hasNoun = False\n",
    "    \n",
    "    for ind, i in enumerate(text_pos):\n",
    "        # store the latest noun in context\n",
    "        if i[1].startswith('NN'):\n",
    "            lastNoun = i\n",
    "            hasNoun = True\n",
    "            currSent.append(i)\n",
    "        # replace any PRP/WDT with last context noun\n",
    "        elif i[1] in ('WDT','PRP'):\n",
    "            if i[0].lower() in ('it', 'itself', 'they', 'them', 'theirs', 'their', 'themselves'):\n",
    "                hasNoun = True\n",
    "                currSent.append(lastNoun)\n",
    "            else:\n",
    "                currSent.append(i)\n",
    "        # break sentence\n",
    "        elif i[1] in ('CC', ',', '.', ':'):\n",
    "            if (hasNoun):\n",
    "                microSent.append(currSent)\n",
    "            elif (currSent):\n",
    "                # for non-empty sentence without noun, insert last context noun at beginning\n",
    "                currSent.insert(0, lastNoun)\n",
    "                microSent.append(currSent)\n",
    "            currSent = []\n",
    "            hasNoun = False\n",
    "            # reset lastNoun to default if sentence ends\n",
    "            if i[1] == '.':\n",
    "                lastNoun = ('product','NN')\n",
    "        else:\n",
    "            currSent.append(i)\n",
    "    \n",
    "    return microSent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EXAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Wow', 'NN')]\n",
      "[('The', 'DT'), ('food', 'NN'), ('was', 'VBD'), ('tasty', 'JJ')]\n",
      "[('food', 'NN'), ('healthy', 'JJ')]\n",
      "[('The', 'DT'), ('price', 'NN'), ('was', 'VBD'), ('slightly', 'RB'), ('expensive', 'JJ')]\n",
      "[('price', 'NN'), ('could', 'MD'), ('have', 'VB'), ('been', 'VBN'), ('better', 'RBR')]\n",
      "[('Packaging', 'NN'), ('was', 'VBD'), ('good', 'JJ'), ('as', 'IN'), ('expected', 'VBN')]\n",
      "[('product', 'NN'), ('Amazing', 'VBG'), ('overall', 'JJ')]\n",
      "[('product', 'NN'), ('Would', 'MD'), ('recommend', 'VB'), ('definitely', 'RB')]\n"
     ]
    }
   ],
   "source": [
    "tempReview = \"\"\"Wow! The food was tasty and healthiy. The price was slightly expnsive, it could have been bettr.\n",
    "                        Pckaging was good as expcted. Amazing overll. Would recommnd defnitely.\"\"\"\n",
    "microSents = reviewToMicroSentences(tempReview)\n",
    "\n",
    "for sent in microSents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SEGREGATION OF MICRO SENTENCES TO EQUIVALENCE CLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, each micro sentence is mapped to one of the equivalence classes depending on the feature of product it talks about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# adds sentence to corresponding aspect class depending on checkTerm\n",
    "def addSentToClass(checkTerm, sent):\n",
    "    \n",
    "    added = True\n",
    "    \n",
    "    # checks if checkTerm contains any substring which maps to some class\n",
    "    # eg flavorful -> flavor -> taste class\n",
    "    # eg unhealthy -> health -> food class\n",
    "    if any(x in checkTerm.lower() for x in tasteClass):\n",
    "        tasteReviews.append(sent)\n",
    "    elif any(x in checkTerm.lower() for x in quantityClass):\n",
    "        quantityReviews.append(sent)\n",
    "    elif any(x in checkTerm.lower() for x in priceClass):\n",
    "        priceReviews.append(sent)\n",
    "    elif any(x in checkTerm.lower() for x in deliveryClass):\n",
    "        deliveryReviews.append(sent)\n",
    "    elif any(x in checkTerm.lower() for x in foodClass):\n",
    "        foodReviews.append(sent)\n",
    "    else:\n",
    "        # Given term cannot decide segregation, need to check other terms\n",
    "        added = False\n",
    "    return added\n",
    "\n",
    "\n",
    "def sentToClasses(sent):\n",
    "\n",
    "    adjList = []\n",
    "    nounList = []\n",
    "    verbList = []\n",
    "    \n",
    "    # find adjectives, verbs, nouns in given sentence\n",
    "    for i in sent:\n",
    "        if i[1].startswith('JJ'):\n",
    "            adjList.append(i)\n",
    "        elif i[1].startswith('NN'):\n",
    "            nounList.append(i)\n",
    "        elif i[1].startswith('V'):\n",
    "            verbList.append(i)\n",
    "\n",
    "    added = False\n",
    "\n",
    "    # Priority segregation : adjectives > verbs > nouns\n",
    "    \n",
    "    # Check for class-specific adjectives (eg tasty, healthy, cheap)\n",
    "    for i in adjList:\n",
    "        if addSentToClass(i[0], sent):\n",
    "            added = True\n",
    "            break\n",
    "\n",
    "    # If no relevant adjective present, check for class-specific verbs (eg delivered)\n",
    "    if not added:\n",
    "        for i in verbList:\n",
    "            if addSentToClass(i[0], sent):\n",
    "                added = True\n",
    "                break\n",
    "    \n",
    "    # If no relevant verb present, check for class-specific nouns (eg product, price, package, taste)\n",
    "    if not added:\n",
    "        for i in nounList:\n",
    "            if addSentToClass(i[0], sent):\n",
    "                added = True\n",
    "                break\n",
    "\n",
    "    # If no relevant noun present, add sentence to misc class\n",
    "    if not added:\n",
    "        miscReviews.append(sent)\n",
    "        \n",
    "\n",
    "def microSentsToClasses(microSents):\n",
    "        \n",
    "    for sent in microSents:\n",
    "        sentToClasses(sent)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EXAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TASTE\n",
      " [[('The', 'DT'), ('food', 'NN'), ('was', 'VBD'), ('tasty', 'JJ')]]\n",
      "\n",
      "QUANTITY\n",
      " []\n",
      "\n",
      "PRICE\n",
      " [[('The', 'DT'), ('price', 'NN'), ('was', 'VBD'), ('slightly', 'RB'), ('expensive', 'JJ')], [('price', 'NN'), ('could', 'MD'), ('have', 'VB'), ('been', 'VBN'), ('better', 'RBR')]]\n",
      "\n",
      "DELIVERY\n",
      " [[('Packaging', 'NN'), ('was', 'VBD'), ('good', 'JJ'), ('as', 'IN'), ('expected', 'VBN')]]\n",
      "\n",
      "PRODUCT\n",
      " [[('food', 'NN'), ('healthy', 'JJ')], [('product', 'NN'), ('Amazing', 'VBG'), ('overall', 'JJ')], [('product', 'NN'), ('Would', 'MD'), ('recommend', 'VB'), ('definitely', 'RB')]]\n",
      "\n",
      "MISC\n",
      " [[('Wow', 'NN')]]\n"
     ]
    }
   ],
   "source": [
    "tasteReviews = []\n",
    "quantityReviews = []\n",
    "priceReviews = []\n",
    "deliveryReviews = []\n",
    "foodReviews = []\n",
    "miscReviews = []\n",
    "\n",
    "microSentsToClasses(microSents)\n",
    "\n",
    "print('TASTE\\n', tasteReviews)\n",
    "print('\\nQUANTITY\\n', quantityReviews)\n",
    "print('\\nPRICE\\n', priceReviews)\n",
    "print('\\nDELIVERY\\n', deliveryReviews)\n",
    "print('\\nPRODUCT\\n', foodReviews)\n",
    "print('\\nMISC\\n', miscReviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANALYZING SENTIMENT OF CLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we score the review in each of the classes on the basis of micro-sentences that are mapped to that equivalence classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DICTIONARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# interjections that directly add to the score irrespective of context\n",
    "absoluteEmphasisDict = {\n",
    "    'wow' : 0.9,\n",
    "    'awesome' : 0.9,\n",
    "    'argh' : -0.7,\n",
    "    'meh' : -0.1,\n",
    "    'eww' : -0.9,\n",
    "    'yuck' : -0.9\n",
    "    \n",
    "}\n",
    "\n",
    "# words which affect the score depending on which other words were in their context\n",
    "relativeEmphasisDict = {\n",
    "    'perfectly' : 1.5,\n",
    "    'extremely' : 1.5,\n",
    "    'absolutely' : 1.5,\n",
    "    'completely' : 1.5,\n",
    "    'awfully' : 1.5,\n",
    "    'very' : 1.3,\n",
    "    'fairly' : 1.1,\n",
    "    'pretty' : 1.1,\n",
    "    'quite' : 1.1,\n",
    "    'almost' : 0.9,\n",
    "    'somewhat' : 0.8,    \n",
    "    'slightly' : 0.7,\n",
    "    'not' : -1,\n",
    "    'never' : -1.5\n",
    "}\n",
    "\n",
    "# Overall emotion of reviewer on basis of total score\n",
    "finalSentDict = {\n",
    "    5 : 'Extremely Satisfied',\n",
    "    4 : 'Extremely Satisfied',\n",
    "    3 : 'Satisfied',\n",
    "    2 : 'Neutral',\n",
    "    1 : 'Dissatisfied',\n",
    "    0 : 'Extremely Dissatisfied'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have used an Emoticon dictionary which contains various text emoticons and their scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emoji</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>:)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>:(</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>:|</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>:]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>:[</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emoji  score\n",
       "0    :)      2\n",
       "1    :(     -2\n",
       "2    :|     -1\n",
       "3    :]      2\n",
       "4    :[     -2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emojiData = pd.read_csv('./emoji.csv')\n",
    "emojiData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emoji</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>:)</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>:(</td>\n",
       "      <td>-0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>:|</td>\n",
       "      <td>-0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>:]</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>:[</td>\n",
       "      <td>-0.714286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  emoji     score\n",
       "0    :)  0.428571\n",
       "1    :( -0.714286\n",
       "2    :| -0.428571\n",
       "3    :]  0.428571\n",
       "4    :[ -0.714286"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizing the score between -1 and 1\n",
    "emojiData['score'] = emojiData['score'].map(lambda x : 2*((x + 3)/7) - 1)\n",
    "emojiData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scoreAspect(aspectSents, addEmoji, review):\n",
    "    \n",
    "    # SenticNet object defined\n",
    "    snObj = SenticNet()\n",
    "    sentCount = len(aspectSents)\n",
    "    totalScore = 0\n",
    "    wordCount = 0\n",
    "    \n",
    "    for sent in aspectSents:\n",
    "        sentScore = 0\n",
    "        relativeFac = 0\n",
    "        for word in sent:\n",
    "            # Calculate sentiment score of adjectives using SenticNet\n",
    "            if word[1].startswith('JJ'):\n",
    "                sentScore += float(snObj.polarity_intense(word[0].lower()))\n",
    "                wordCount += 1\n",
    "            # Directly add sentiment score of interjections (eg wow, yuck)\n",
    "            elif word[0].lower() in absoluteEmphasisDict:\n",
    "                sentScore += absoluteEmphasisDict[word[0].lower()]\n",
    "                wordCount += 1\n",
    "            # Store intensity of relativeEmphasis words (eg very, slightly)\n",
    "            elif word[0].lower() in relativeEmphasisDict:\n",
    "                relativeFac += relativeEmphasisDict[word[0].lower()]\n",
    "        # If relative emphasis words are present, multiply their magnitude to the score of sentence\n",
    "        if relativeFac != 0:\n",
    "            sentScore *= relativeFac\n",
    "        # Add score of micro-sentence to total score of aspect\n",
    "        totalScore += sentScore\n",
    "     \n",
    "    # Misc Reviews aspect\n",
    "    if addEmoji:\n",
    "        emojiScore = 0\n",
    "        emojiCount = 0\n",
    "        for ind, emoji in emojiData.iterrows():\n",
    "            if emoji['emoji'] in review:\n",
    "                emojiScore += emoji['score']\n",
    "                emojiCount += 1\n",
    "                # Add present emoji to miscReviews\n",
    "                miscReviews.append([(emoji['emoji'], 'EMJ')])\n",
    "        \n",
    "        wordCount += emojiCount\n",
    "        totalScore += emojiScore\n",
    "    \n",
    "    # Normalise totalScore to between [0,5]\n",
    "    if wordCount!= 0:\n",
    "        totalScore = totalScore/wordCount\n",
    "        return ((totalScore*1.8) + 2.5)\n",
    "    # If no micro-sentence present for given aspect, return -1\n",
    "    else:\n",
    "        return -1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EXAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0282"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasteReviews = []\n",
    "quantityReviews = []\n",
    "priceReviews = []\n",
    "deliveryReviews = []\n",
    "foodReviews = []\n",
    "miscReviews = []\n",
    "\n",
    "review = \"\"\"The food was good.\"\"\"\n",
    "\n",
    "microSents = reviewToMicroSentences(review)    \n",
    "microSentsToClasses(microSents)\n",
    "scoreAspect(foodReviews, False, review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9718\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "tasteReviews = []\n",
    "quantityReviews = []\n",
    "priceReviews = []\n",
    "deliveryReviews = []\n",
    "foodReviews = []\n",
    "miscReviews = []\n",
    "\n",
    "review = \"\"\"The food was not good.\"\"\"\n",
    "\n",
    "microSents = reviewToMicroSentences(review)    \n",
    "microSentsToClasses(microSents)\n",
    "print(scoreAspect(foodReviews, False, review))\n",
    "print(scoreAspect(miscReviews, True, review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.7923\n",
      "-1\n"
     ]
    }
   ],
   "source": [
    "tasteReviews = []\n",
    "quantityReviews = []\n",
    "priceReviews = []\n",
    "deliveryReviews = []\n",
    "foodReviews = []\n",
    "miscReviews = []\n",
    "\n",
    "review = \"\"\"The food was extremely good.\"\"\"\n",
    "\n",
    "microSents = reviewToMicroSentences(review)    \n",
    "microSentsToClasses(microSents)\n",
    "print(scoreAspect(foodReviews, False, review))\n",
    "print(scoreAspect(miscReviews, True, review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0282\n",
      "3.2714285714285714\n"
     ]
    }
   ],
   "source": [
    "tasteReviews = []\n",
    "quantityReviews = []\n",
    "priceReviews = []\n",
    "deliveryReviews = []\n",
    "foodReviews = []\n",
    "miscReviews = []\n",
    "\n",
    "review = \"\"\"The food was good. :)\"\"\"\n",
    "\n",
    "microSents = reviewToMicroSentences(review)    \n",
    "microSentsToClasses(microSents)\n",
    "print(scoreAspect(foodReviews, False, review))\n",
    "print(scoreAspect(miscReviews, True, review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.73634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('The', 'DT'),\n",
       "  ('price', 'NN'),\n",
       "  ('was', 'VBD'),\n",
       "  ('also', 'RB'),\n",
       "  ('very', 'RB'),\n",
       "  ('cheap', 'JJ')]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasteReviews = []\n",
    "quantityReviews = []\n",
    "priceReviews = []\n",
    "deliveryReviews = []\n",
    "foodReviews = []\n",
    "miscReviews = []\n",
    "\n",
    "review = \"\"\"The price was also very cheap.\"\"\"\n",
    "\n",
    "microSents = reviewToMicroSentences(review)    \n",
    "microSentsToClasses(microSents)\n",
    "print(scoreAspect(priceReviews, False, review))\n",
    "priceReviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PUTTING IT TOGETHER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints micro-sentences belonging to the aspect and its score\n",
    "def printAspect(heading, aspectReviews, review):\n",
    "    \n",
    "    print('\\n', heading)\n",
    "    \n",
    "    # Consider Emoticons under Misc Reviews class\n",
    "    if heading == 'MISC':\n",
    "        score = scoreAspect(aspectReviews, True, review)\n",
    "    else:\n",
    "        score = scoreAspect(aspectReviews, False, review)\n",
    "    \n",
    "    # Prints the micro-sentences belonging to that aspect\n",
    "    for sent in aspectReviews:\n",
    "        for word in sent:\n",
    "            print(word[0], end=' ')\n",
    "        print()\n",
    "    \n",
    "    # Score should remain between [0,5]\n",
    "    if score > 5:\n",
    "        score = 5\n",
    "    elif (score != -1) & (score < 0):\n",
    "        score = 0\n",
    "    \n",
    "    # Score -1 means no micro-sentence present for that class (ie reviewer did not comment about that aspect)\n",
    "    if score != -1:\n",
    "        print('Score = %.2f' % score)\n",
    "    else:\n",
    "        print('Score = NA')\n",
    "        \n",
    "    return score\n",
    "\n",
    "\n",
    "def analyseReview(review):\n",
    "\n",
    "    # Break review into micro-sentences and print them\n",
    "    microSents = reviewToMicroSentences(review)\n",
    "    \n",
    "    print(' MICRO-SENTENCES :')\n",
    "    for sent in microSents:\n",
    "        for word in sent:\n",
    "            print(word[0], end=' ')\n",
    "        print()\n",
    "    \n",
    "    # Map micro-sentences to aspect classes\n",
    "    microSentsToClasses(microSents)\n",
    "    \n",
    "    allScores = []\n",
    "    # Calculate and print individual scores\n",
    "    allScores.append(printAspect('TASTE', tasteReviews, review))\n",
    "    allScores.append(printAspect('QUANTITY', quantityReviews, review))\n",
    "    allScores.append(printAspect('PRICE', priceReviews, review))\n",
    "    allScores.append(printAspect('DELIVERY', deliveryReviews, review))\n",
    "    allScores.append(printAspect('PRODUCT', foodReviews, review))\n",
    "    allScores.append(printAspect('MISC', miscReviews, review))\n",
    "    \n",
    "    # Calculate and print overall emotion of reviewer\n",
    "    validScores = [score for score in allScores if score != -1]\n",
    "    overallScore = int(sum(validScores)/len(validScores))\n",
    "    print('\\n OVERALL SCORE : %.2f' % (sum(validScores)/len(validScores)))\n",
    "    print('\\n OVERALL EMOTION :', finalSentDict[overallScore])\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EXAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MICRO-SENTENCES :\n",
      "product Amazing \n",
      "The product was healthy \n",
      "product tasty \n",
      "The packet had a good number of chips as well \n",
      "I was not satisfied with the price though \n",
      "price could have been cheaper \n",
      "product was delivered on time as expected \n",
      "the packaging was sturdy \n",
      "product Overall good \n",
      "product would recommend \n",
      "\n",
      " TASTE\n",
      "product tasty \n",
      "Score = 2.59\n",
      "\n",
      " QUANTITY\n",
      "The packet had a good number of chips as well \n",
      "Score = 4.03\n",
      "\n",
      " PRICE\n",
      "I was not satisfied with the price though \n",
      "price could have been cheaper \n",
      "Score = 0.95\n",
      "\n",
      " DELIVERY\n",
      "product was delivered on time as expected \n",
      "the packaging was sturdy \n",
      "Score = 2.37\n",
      "\n",
      " PRODUCT\n",
      "product Amazing \n",
      "The product was healthy \n",
      "product Overall good \n",
      "product would recommend \n",
      "Score = 3.02\n",
      "\n",
      " MISC\n",
      "Score = NA\n",
      "\n",
      " OVERALL EMOTION : Neutral\n"
     ]
    }
   ],
   "source": [
    "tempReview = \"\"\"Amazing! The product was healthy and tasty. The packet had a good number of chips as well. \n",
    "    I was not satisfied with the price though, it could have been cheaper. \n",
    "    It was delivered on time as expected, and the packaging was sturdy. Overall good, would recommend.\"\"\"\n",
    "\n",
    "tasteReviews = []\n",
    "quantityReviews = []\n",
    "priceReviews = []\n",
    "deliveryReviews = []\n",
    "foodReviews = []\n",
    "miscReviews = []\n",
    "\n",
    "analyseReview(tempReview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MICRO-SENTENCES :\n",
      "The food sucked \n",
      "product was unhealthy \n",
      "product poor \n",
      "The packaging was damaged as well \n",
      "product Never buying this again \n",
      "product was very expensive \n",
      "\n",
      " TASTE\n",
      "Score = NA\n",
      "\n",
      " QUANTITY\n",
      "Score = NA\n",
      "\n",
      " PRICE\n",
      "product was very expensive \n",
      "Score = 0.49\n",
      "\n",
      " DELIVERY\n",
      "The packaging was damaged as well \n",
      "Score = NA\n",
      "\n",
      " PRODUCT\n",
      "The food sucked \n",
      "product was unhealthy \n",
      "product poor \n",
      "product Never buying this again \n",
      "Score = 2.05\n",
      "\n",
      " MISC\n",
      ":( \n",
      "Score = 1.21\n",
      "\n",
      " OVERALL EMOTION : Dissatisfied\n"
     ]
    }
   ],
   "source": [
    "tempReview = \"\"\"The food sucked. It was unhealthy and poor. The packaging was damaged as well. Never buying this again.\n",
    "    It was very expensive. :(\"\"\"\n",
    "\n",
    "tasteReviews = []\n",
    "quantityReviews = []\n",
    "priceReviews = []\n",
    "deliveryReviews = []\n",
    "foodReviews = []\n",
    "miscReviews = []\n",
    "\n",
    "analyseReview(tempReview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MICRO-SENTENCES :\n",
      "product Awesome \n",
      "product was very tasty \n",
      "product extremely healthy \n",
      "The price was not at all expensive \n",
      "product was delivered extremely fast \n",
      "The number of items in the packet was also enough to satisfy \n",
      "\n",
      " TASTE\n",
      "product was very tasty \n",
      "Score = 2.62\n",
      "\n",
      " QUANTITY\n",
      "The number of items in the packet was also enough to satisfy \n",
      "Score = NA\n",
      "\n",
      " PRICE\n",
      "The price was not at all expensive \n",
      "Score = 4.05\n",
      "\n",
      " DELIVERY\n",
      "product was delivered extremely fast \n",
      "Score = 2.89\n",
      "\n",
      " PRODUCT\n",
      "product Awesome \n",
      "product extremely healthy \n",
      "Score = 4.35\n",
      "\n",
      " MISC\n",
      "xo \n",
      "Score = 3.79\n",
      "\n",
      " OVERALL SCORE : 3.54\n",
      "\n",
      " OVERALL EMOTION : Satisfied\n"
     ]
    }
   ],
   "source": [
    "tempReview = \"\"\"Awesome! It was very tasty and extremely healthy. The price was not at all expensive. \n",
    "            It was delivered extremely fast. The number of items in the packet was also enough to satisfy. xo\"\"\"\n",
    "\n",
    "tasteReviews = []\n",
    "quantityReviews = []\n",
    "priceReviews = []\n",
    "deliveryReviews = []\n",
    "foodReviews = []\n",
    "miscReviews = []\n",
    "\n",
    "analyseReview(tempReview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " MICRO-SENTENCES :\n",
      "Wow \n",
      "What a tasty chocolate \n",
      "what a reasonable price \n",
      "I was wrong to buy Hershey is for all this time just because of the name \n",
      "name were really expensive \n",
      "Had I come across this chocolate sooner \n",
      "I would never have bought another brand ever \n",
      "\n",
      " TASTE\n",
      "What a tasty chocolate \n",
      "Score = 2.59\n",
      "\n",
      " QUANTITY\n",
      "Score = NA\n",
      "\n",
      " PRICE\n",
      "what a reasonable price \n",
      "name were really expensive \n",
      "Score = 1.69\n",
      "\n",
      " DELIVERY\n",
      "Score = NA\n",
      "\n",
      " PRODUCT\n",
      "Had I come across this chocolate sooner \n",
      "I would never have bought another brand ever \n",
      "Score = NA\n",
      "\n",
      " MISC\n",
      "Wow \n",
      "I was wrong to buy Hershey is for all this time just because of the name \n",
      "xo \n",
      "Score = 3.01\n",
      "\n",
      " OVERALL SCORE : 2.43\n",
      "\n",
      " OVERALL EMOTION : Neutral\n"
     ]
    }
   ],
   "source": [
    "tempReview = \"\"\"Wow! What a tasty chocolate. And what a reasonable price. I was wrong to buy Hershey's for all this time just\n",
    "            because of the name, and they were really expensive. Had I come across this chocolate sooner, I would never have bought\n",
    "            another brand ever. xo\"\"\"\n",
    "\n",
    "tasteReviews = []\n",
    "quantityReviews = []\n",
    "priceReviews = []\n",
    "deliveryReviews = []\n",
    "foodReviews = []\n",
    "miscReviews = []\n",
    "\n",
    "analyseReview(tempReview)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
